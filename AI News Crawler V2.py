import os
import datetime
import requests
from openai import OpenAI

# ===== é…ç½®åŒº =====
DASHSCOPE_API_KEY = "sk-ä½ çš„APIå¯†é’¥"  # â† æ›¿æ¢ä¸ºä½ è‡ªå·±çš„Key
BLOG_TITLE = "AIå‰æ²¿é€Ÿé€’"
AUTHOR = "ä½ çš„åå­—"

# æ–°é—»æºï¼ˆå¯æ‰©å±•ï¼‰
NEWS_SOURCES = [
    "https://arxiv.org/list/cs.AI/recent",
    "https://deepmind.google/blog/",
    "https://openai.com/blog",
    # å¯æ·»åŠ æ›´å¤š
]

# ===== å·¥å…·å‡½æ•° =====
def fetch_news_snippets():
    """æ¨¡æ‹ŸæŠ“å–æ–°é—»æ ‡é¢˜å’Œæ‘˜è¦ï¼ˆå®é™…å¯æ›¿æ¢ä¸ºçœŸå®çˆ¬è™«ï¼‰"""
    # TODO: è¿™é‡Œå¯é›†æˆ BeautifulSoup æˆ–è°ƒç”¨ RSS/ArXiv API
    return [
        "Google DeepMind å‘å¸ƒæ–°ä¸€ä»£æ¨ç†æ¨¡å‹ Gemini 2.5",
        "OpenAI æ¨å‡º o1-miniï¼Œä¸“æ³¨ä»£ç ç”Ÿæˆä¸æ•°å­¦æ¨ç†",
        "Meta å¼€æº Llama 4-Miniï¼Œæ”¯æŒ 128K ä¸Šä¸‹æ–‡",
        "ä¸­å›½å›¢é˜Ÿåœ¨ NeurIPS 2025 æå‡ºæ–°å‹è§†è§‰-è¯­è¨€å¯¹é½æ–¹æ³•"
    ]

def generate_summary_with_bailian(news_list):
    """è°ƒç”¨é˜¿é‡Œç™¾ç‚¼ç”Ÿæˆæ€»ç»“æ–‡ç« """
    client = OpenAI(
        api_key=DASHSCOPE_API_KEY,
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
    )
    
    prompt = f"""ä½ æ˜¯ä¸€ä½ç§‘æŠ€ä¸“æ ä½œå®¶ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä»Šæ—¥AIé¢†åŸŸåŠ¨æ€ï¼Œæ’°å†™ä¸€ç¯‡800å­—å·¦å³çš„ä¸­æ–‡åšå®¢æ–‡ç« ï¼š
- æ ‡é¢˜è¦å¸å¼•äºº
- åˆ†æ®µæ¸…æ™°ï¼ˆå¼•è¨€ã€ä¸»ä½“ã€å±•æœ›ï¼‰
- è¯­è¨€ä¸“ä¸šä½†æ˜“æ‡‚
- ç»“å°¾é¼“åŠ±è¯»è€…æ€è€ƒ

ä»Šæ—¥åŠ¨æ€ï¼š
{chr(10).join(f'- {item}' for item in news_list)}

è¯·ç›´æ¥è¾“å‡ºæ–‡ç« å†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•è¯´æ˜æ–‡å­—ã€‚"""

    try:
        response = client.chat.completions.create(
            model="qwen-plus",  # å¹³è¡¡æ•ˆæœä¸æˆæœ¬
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"è°ƒç”¨ç™¾ç‚¼å¤±è´¥: {e}")
        return "ä»Šæ—¥AIåŠ¨æ€æ€»ç»“ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–APIé…é¢ã€‚"

def render_html(title, date_str, content):
    """æ¸²æŸ“å•ç¯‡æ–‡ç« HTML"""
    return f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>{title} - {BLOG_TITLE}</title>
    <link rel="stylesheet" href="/static/style.css">
</head>
<body>
    <header><h1>{BLOG_TITLE}</h1></header>
    <main>
        <article>
            <h2>{title}</h2>
            <p class="meta">å‘å¸ƒäº {date_str} | ä½œè€… {AUTHOR}</p>
            <div class="content">
                {content.replace(chr(10), '<br>')}
            </div>
        </article>
    </main>
    <footer><a href="/">â† è¿”å›é¦–é¡µ</a></footer>
</body>
</html>"""

def build_index(posts_info):
    """ç”Ÿæˆé¦–é¡µ"""
    items_html = ""
    for post in sorted(posts_info, key=lambda x: x['date'], reverse=True):
        items_html += f'<li><a href="{post["url"]}">{post["title"]}</a> ({post["date"]})</li>'
    
    return f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>{BLOG_TITLE}</title>
    <link rel="stylesheet" href="/static/style.css">
</head>
<body>
    <header><h1>{BLOG_TITLE}</h1></header>
    <main>
        <h2>æœ€æ–°æ–‡ç« </h2>
        <ul>{items_html}</ul>
    </main>
    <footer>Powered by Python + é˜¿é‡Œç™¾ç‚¼</footer>
</body>
</html>"""

# ===== ä¸»æµç¨‹ =====
def main():
    today = datetime.date.today()
    date_str = today.strftime("%Y-%m-%d")
    filename = f"{date_str}-ai-daily.html"
    
    print("ğŸ” æ­£åœ¨æŠ“å–AIæ–°é—»...")
    news = fetch_news_snippets()
    
    print("ğŸ§  æ­£åœ¨è°ƒç”¨é˜¿é‡Œç™¾ç‚¼ç”Ÿæˆæ€»ç»“...")
    summary = generate_summary_with_bailian(news)
    
    print("ğŸ“ æ­£åœ¨ç”Ÿæˆæ–‡ç« é¡µé¢...")
    title = f"AIå‰æ²¿é€Ÿé€’ | {date_str}"
    html_content = render_html(title, date_str, summary)
    
    # åˆ›å»ºç›®å½•
    os.makedirs("posts", exist_ok=True)
    os.makedirs("static", exist_ok=True)
    
    # ä¿å­˜æ–‡ç« 
    with open(f"posts/{filename}", "w", encoding="utf-8") as f:
        f.write(html_content)
    
    # ç”Ÿæˆé¦–é¡µ
    posts_info = []
    for f in os.listdir("posts"):
        if f.endswith(".html"):
            date_part = f.split("-ai-daily")
            posts_info.append({
                "title": f"AIå‰æ²¿é€Ÿé€’ | {date_part}",
                "date": date_part,
                "url": f"/posts/{f}"
            })
    
    with open("index.html", "w", encoding="utf-8") as f:
        f.write(build_index(posts_info))
    
    # åˆ›å»ºç®€å•CSSï¼ˆé¦–æ¬¡è¿è¡Œæ—¶ï¼‰
    if not os.path.exists("static/style.css"):
        with open("static/style.css", "w") as f:
            f.write("""
body { font-family: 'Segoe UI', sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; line-height: 1.6; }
header h1 { color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; }
.meta { color: #7f8c8d; font-style: italic; }
.content { margin: 20px 0; }
footer { margin-top: 40px; text-align: center; color: #95a5a6; }
""")
    
    print(f"âœ… ä»Šæ—¥åšå®¢å·²ç”Ÿæˆï¼\n   æ–‡ç« è·¯å¾„: posts/{filename}\n   è¯·æäº¤åˆ° GitHub å¹¶è®¿é—®ä½ çš„ Pages ç«™ç‚¹ã€‚")

if __name__ == "__main__":
    main()
