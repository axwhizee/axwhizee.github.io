# -*- coding: utf-8 -*-
"""
AI é¢†åŸŸå‘¨æŠ¥ç”Ÿæˆå™¨

åŠŸèƒ½æ¦‚è¿°ï¼š
1. ä»å¤šä¸ªé¡¶çº§ AI æœºæ„çš„ RSS æºæŠ“å–æœ€è¿‘ 7 å¤©å†…çš„æ–‡ç« ï¼›
2. æå–æ¯ç¯‡æ–‡ç« çš„æ ‡é¢˜ã€é“¾æ¥ã€æ‘˜è¦å’Œæ¥æºï¼›
3. å°†æ±‡æ€»ä¿¡æ¯é€šè¿‡é˜¿é‡Œäº‘ç™¾ç‚¼ï¼ˆDashScopeï¼‰çš„ Qwen-Max æ¨¡å‹ï¼ˆå…¼å®¹ OpenAI APIï¼‰ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„ Markdown å‘¨æŠ¥ï¼›
4. å°†æœ€ç»ˆæŠ¥å‘Šå†™å…¥æœ¬åœ°æ–‡ä»¶ `AI_Weekly_Report.md`ã€‚

ä¾èµ–åº“è¯´æ˜ï¼š
- feedparserï¼šè§£æ RSS/Atom è®¢é˜…æº
- requestsï¼šå‘èµ· HTTP è¯·æ±‚è·å– RSS å†…å®¹
- openaiï¼šä½¿ç”¨ OpenAI å…¼å®¹æ¥å£è°ƒç”¨ DashScope çš„å¤§æ¨¡å‹
- datetime / email.utilsï¼šå¤„ç†ä¸åŒæ ¼å¼çš„å‘å¸ƒæ—¶é—´
"""

import feedparser
import requests
from datetime import datetime, timedelta, timezone
from email.utils import parsedate_tz, mktime_tz  # ç”¨äºè§£æ RFC 2822 æ ¼å¼çš„æ—¥æœŸï¼ˆå¸¸è§äº RSSï¼‰
from openai import OpenAI
import os

DASHSCOPE_API_KEY = os.environ.get("DASHSCOPE_API_KEY") # ç¯å¢ƒå˜é‡ä¸­è¯»å–DashScope APIå¯†é’¥

# å®šä¹‰è¦ç›‘æ§çš„ AI é¢†åŸŸæƒå¨åšå®¢ RSS åœ°å€åˆ—è¡¨
RSS_SOURCES = [
    "https://research.google/blog/rss/",        # Google AI Blog
    "https://openai.com/news/rss.xml",          # OpenAI Blog
    "https://deepmind.com/blog/feed/",          # DeepMind Blog
    "https://huggingface.co/blog/feed.xml",     # Hugging Face Blog
    "https://bair.berkeley.edu/blog/feed.xml"   # BAIR (Berkeley AI Research)
]

# è®¡ç®—â€œ7å¤©å‰â€çš„ UTC æ—¶é—´ç‚¹ï¼Œç”¨äºè¿‡æ»¤è¿‘æœŸæ–‡ç« 
SEVEN_DAYS_AGO = datetime.now(timezone.utc) - timedelta(days=7)

def parse_rss_date(date_str):
    """
    å°è¯•å°† RSS ä¸­çš„æ—¥æœŸå­—ç¬¦ä¸²è§£æä¸ºæ ‡å‡†çš„ datetime å¯¹è±¡ï¼ˆæ— æ—¶åŒºä¿¡æ¯ï¼Œä½†æŒ‰ UTC å¤„ç†ï¼‰ã€‚
    
    RSS ä¸­çš„æ—¥æœŸæ ¼å¼ä¸ç»Ÿä¸€ï¼Œå¯èƒ½ä¸ºï¼š
    - RFC 2822 æ ¼å¼ï¼ˆå¦‚ "Mon, 01 Jan 2024 12:00:00 GMT"ï¼‰
    - ISO 8601 æ ¼å¼ï¼ˆå¦‚ "2024-01-01T12:00:00Z" æˆ–å¸¦æ—¶åŒºåç§»ï¼‰
    
    å‚æ•°:
        date_str (str): åŸå§‹æ—¥æœŸå­—ç¬¦ä¸²ï¼ˆå¯èƒ½æ¥è‡ª entry.published æˆ– entry.updatedï¼‰
    
    è¿”å›:
        datetime | None: æˆåŠŸè§£æåˆ™è¿”å› naive datetimeï¼ˆè§†ä¸º UTCï¼‰ï¼Œå¦åˆ™è¿”å› None
    """
    if not date_str:
        return None

    # é¦–å…ˆå°è¯•ä½¿ç”¨ email.utils è§£æ RFC 2822 æ ¼å¼ï¼ˆæœ€å¸¸è§äº RSSï¼‰
    try:
        parsed_tuple = parsedate_tz(date_str)
        if parsed_tuple:
            timestamp = mktime_tz(parsed_tuple)  # è½¬ä¸º Unix æ—¶é—´æˆ³ï¼ˆè€ƒè™‘æ—¶åŒºï¼‰
            dt = datetime.fromtimestamp(timestamp, tz=timezone.utc)
            return dt.replace(tzinfo=None)  # è¿”å›æ— æ—¶åŒºå¯¹è±¡ï¼Œä½†å†…å®¹æ˜¯ UTC æ—¶é—´
    except Exception:
        pass  # è‹¥å¤±è´¥ï¼Œç»§ç»­å°è¯•å…¶ä»–æ ¼å¼

    # è‹¥ä¸Šè¿°å¤±è´¥ï¼Œå°è¯•å‡ ç§å¸¸è§çš„ ISO æ ¼å¼
    for fmt in ["%Y-%m-%dT%H:%M:%S%z", "%Y-%m-%dT%H:%M:%SZ", "%Y-%m-%d %H:%M:%S%z"]:
        try:
            dt = datetime.strptime(date_str, fmt)
            # å¦‚æœè§£æç»“æœæ²¡æœ‰æ—¶åŒºä¿¡æ¯ï¼Œåˆ™é»˜è®¤ä¸º UTC
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=timezone.utc)
            # è½¬æ¢ä¸º UTC å¹¶å»é™¤æ—¶åŒºä¿¡æ¯ï¼ˆä¿æŒä¸ä¸Šä¸€åˆ†æ”¯ä¸€è‡´ï¼‰
            return dt.astimezone(timezone.utc).replace(tzinfo=None)
        except ValueError:
            continue  # æ ¼å¼ä¸åŒ¹é…ï¼Œå°è¯•ä¸‹ä¸€ä¸ª

    # æ‰€æœ‰å°è¯•å‡å¤±è´¥
    return None

def fetch_recent_articles():
    """
    ä»é¢„è®¾çš„ RSS æºæŠ“å–æœ€è¿‘ 7 å¤©å†…å‘å¸ƒçš„æ–‡ç« ï¼Œå¹¶æå–å…³é”®ä¿¡æ¯ã€‚
    
    è¿”å›:
        list[dict]: åŒ…å«æ–‡ç« ä¿¡æ¯çš„å­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«ï¼š
            - title: æ–‡ç« æ ‡é¢˜
            - link: åŸæ–‡é“¾æ¥
            - summary: æ‘˜è¦ï¼ˆæˆªæ–­è‡³ 800 å­—ç¬¦ï¼Œå»é™¤æ¢è¡Œï¼‰
            - source: æ¥æºåšå®¢åç§°
            - published: å‘å¸ƒæ—¶é—´ï¼ˆISO æ ¼å¼å­—ç¬¦ä¸²ï¼ŒUTCï¼‰
    """
    articles = []

    for url in RSS_SOURCES:
        try:
            print(f"Fetching: {url}")
            # å‘èµ· GET è¯·æ±‚è·å– RSS å†…å®¹ï¼Œè®¾ç½®è¶…æ—¶é˜²æ­¢å¡æ­»
            resp = requests.get(url, timeout=10)
            resp.raise_for_status()  # è‹¥çŠ¶æ€ç é 2xx åˆ™æŠ›å‡ºå¼‚å¸¸
            
            # ä½¿ç”¨ feedparser è§£æ RSS å†…å®¹
            feed = feedparser.parse(resp.content)

            # éå†æ¯ç¯‡æ–‡ç« ï¼ˆentryï¼‰
            for entry in feed.entries:
                # ä¼˜å…ˆä½¿ç”¨ 'published'ï¼Œè‹¥æ— åˆ™å°è¯• 'updated'
                date_str = getattr(entry, 'published', None) or getattr(entry, 'updated', None)
                pub_date = parse_rss_date(date_str) if date_str else None

                # ä»…ä¿ç•™è¿‡å» 7 å¤©å†…çš„æ–‡ç« ï¼ˆæ³¨æ„ï¼šSEVEN_DAYS_AGO æ˜¯å¸¦æ—¶åŒºçš„ï¼Œéœ€å¯¹é½ï¼‰
                if pub_date and pub_date >= SEVEN_DAYS_AGO.replace(tzinfo=None):
                    title = getattr(entry, 'title', 'No Title').strip()
                    link = getattr(entry, 'link', '').strip()
                    # è·å–æ‘˜è¦å¹¶åšç®€å•æ¸…æ´—ï¼šå»æ¢è¡Œã€æˆªæ–­
                    summary = getattr(entry, 'summary', '').strip().replace('\n', ' ')[:800]
                    source = getattr(feed.feed, 'title', 'Unknown Source').strip()

                    articles.append({
                        'title': title,
                        'link': link,
                        'summary': summary,
                        'source': source,
                        'published': pub_date.isoformat()  # è½¬ä¸º ISO å­—ç¬¦ä¸²ä¾¿äºæ’åºå’Œè¾“å‡º
                    })
                    
        except Exception as e:
            # æ•è·ä»»æ„å¼‚å¸¸ï¼ˆç½‘ç»œé”™è¯¯ã€è§£æå¤±è´¥ç­‰ï¼‰ï¼Œè®°å½•æ—¥å¿—ä½†ä¸ä¸­æ–­æ•´ä½“æµç¨‹
            print(f"âš ï¸ Error fetching {url}: {e}")
            continue

    # æŒ‰å‘å¸ƒæ—¶é—´å€’åºæ’åˆ—ï¼ˆæœ€æ–°åœ¨å‰ï¼‰
    articles.sort(key=lambda x: x['published'], reverse=True)
    return articles

def generate_weekly_report(articles):
    """
    è°ƒç”¨ DashScope çš„ Qwen-Max æ¨¡å‹ï¼ˆé€šè¿‡ OpenAI å…¼å®¹ APIï¼‰ç”Ÿæˆ AI å‘¨æŠ¥ã€‚
    
    å‚æ•°:
        articles (list): ç”± fetch_recent_articles è¿”å›çš„æ–‡ç« åˆ—è¡¨
    
    è¿”å›:
        str: ç”Ÿæˆçš„ Markdown æ ¼å¼å‘¨æŠ¥å†…å®¹ï¼Œæˆ–é”™è¯¯ä¿¡æ¯
    """
    if not articles:
        return "# AIé¢†åŸŸæœ€æ–°è¿›å±•å‘¨æŠ¥\n\næœ¬å‘¨æ— æ–°å‘å¸ƒå†…å®¹ã€‚"

    # æ„å»ºæä¾›ç»™å¤§æ¨¡å‹çš„åŸå§‹ä¸Šä¸‹æ–‡
    content = "ä»¥ä¸‹æ˜¯è¿‡å»ä¸€å‘¨æ¥è‡ª Google AIã€OpenAIã€DeepMindã€Hugging Face å’Œ BAIR ç­‰é¡¶çº§ AI æœºæ„çš„æœ€æ–°æ–‡ç« æ‘˜è¦ï¼š\n\n"
    for art in articles:
        content += f"- **{art['title']}** ï¼ˆæ¥æºï¼š{art['source']}ï¼‰\n"
        if art['summary']:
            content += f"  æ‘˜è¦ï¼š{art['summary']}\n"
        content += f"  é“¾æ¥ï¼š{art['link']}\n\n"

    # æ„é€ æç¤ºè¯ï¼ˆPromptï¼‰ï¼Œæ˜ç¡®è¦æ±‚æ¨¡å‹è¾“å‡ºç»“æ„åŒ–ã€æœ‰æ´å¯ŸåŠ›çš„åˆ†æ
    prompt = f"""è¯·åŸºäºä»¥ä¸‹è¿‘æœŸ AI é¢†åŸŸçš„æŠ€æœ¯åšå®¢æ‘˜è¦ï¼Œæ’°å†™ä¸€ä»½åä¸ºã€ŠAIé¢†åŸŸæœ€æ–°è¿›å±•å‘¨æŠ¥ã€‹çš„æŠ¥å‘Šã€‚

è¦æ±‚ï¼š
1. æŠ¥å‘Šå¿…é¡»ä½¿ç”¨ Markdown æ ¼å¼ï¼›
2. æ ‡é¢˜ä¸ºï¼š**AIé¢†åŸŸæœ€æ–°è¿›å±•å‘¨æŠ¥**ï¼›
3. å†…å®¹éœ€åŒ…å«ï¼š
   - å½“å‰ä¸»è¦å‘å±•æ–¹å‘ï¼ˆå¦‚å¤šæ¨¡æ€ã€æ¨ç†èƒ½åŠ›ã€å¼€æºç”Ÿæ€ã€å…·èº«æ™ºèƒ½ç­‰ï¼‰ï¼›
   - æœ¬å‘¨çªå‡ºçš„æµè¡Œäº§å“æˆ–æŠ€æœ¯ï¼ˆå¦‚æ–°æ¨¡å‹ã€æ¡†æ¶ã€å·¥å…·ï¼‰ï¼›
4. ä¸¥ç¦è™šæ„æœªåœ¨è¾“å…¥ä¸­æåŠçš„ä¿¡æ¯ï¼Œæ‰€æœ‰ç»“è®ºå¿…é¡»åŸºäºæ‰€æä¾›å†…å®¹ï¼›
5. è¯­è¨€é£æ ¼ï¼šä¸“ä¸šã€ç®€æ´ã€æœ‰æ´å¯ŸåŠ›ï¼Œé¿å…ç®€å•ç½—åˆ—ã€‚

ä»¥ä¸‹æ˜¯åŸå§‹ä¿¡æ¯ï¼š
{content}
"""

    # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼ŒæŒ‡å‘ DashScope çš„å…¼å®¹ API ç«¯ç‚¹
    client = OpenAI(
        api_key=DASHSCOPE_API_KEY,
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
    )

    try:
        # è°ƒç”¨ Qwen-Max æ¨¡å‹ç”ŸæˆæŠ¥å‘Š
        response = client.chat.completions.create(
            model="qwen-max",
            messages=[
                {
                    'role': 'system',
                    'content': (
                        'ä½ æ˜¯ä¸€ä½èµ„æ·± AI è¡Œä¸šåˆ†æå¸ˆï¼Œä½ çš„æªè¾åº”å½“ï¼šä¸“ä¸šã€ç®€æ´ã€æœ‰æ´å¯ŸåŠ›ï¼Œé¿å…ç½—åˆ—ï¼Œ'
                        'ä¸”å°¤å…¶æ³¨æ„ï¼šä¸è¦è™šæ„æœªæåŠçš„å†…å®¹ï¼Œä»…åŸºäºæ‰€æä¾›ä¸æœç´¢åˆ°çš„èµ„æ–™ä¿¡æ¯æ¨ç†ã€‚'
                    )
                },
                {'role': 'user', 'content': prompt}
            ],
            temperature=0.3,      # è¾ƒä½æ¸©åº¦ä»¥ä¿è¯è¾“å‡ºç¨³å®šæ€§å’Œäº‹å®æ€§
            max_tokens=3000       # å…è®¸ç”Ÿæˆè¾ƒé•¿æŠ¥å‘Š
        )
        content = response.choices[0].message.content
        # å®‰å…¨è®¿é—®usage
        total_tokens = response.usage.total_tokens if response.usage else None
        return content, total_tokens
    except Exception as e:
        # è‹¥è°ƒç”¨å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯åŠåŸå§‹æ–‡ç« æ•°é‡ä¾›è°ƒè¯•
        return f"# AIé¢†åŸŸæœ€æ–°è¿›å±•å‘¨æŠ¥\n\nâŒ ç”Ÿæˆå¤±è´¥ï¼š{str(e)}\n\nå…±æŠ“å– {len(articles)} ç¯‡æ–‡ç« ã€‚"

if __name__ == "__main__":
    """
    ä¸»ç¨‹åºå…¥å£ï¼š
    1. æŠ“å–æ–‡ç« 
    2. ç”ŸæˆæŠ¥å‘Š
    3. å†™å…¥ Markdown æ–‡ä»¶
    """
    print("æ­£åœ¨æŠ“å–æœ€è¿‘7å¤©çš„AIå‰æ²¿æ–‡ç« ...")
    articles = fetch_recent_articles()
    print(f"âœ… å…±è·å– {len(articles)} ç¯‡æ–°æ–‡ç« ã€‚")

    print("æ­£åœ¨è°ƒç”¨ Qwen-Maxï¼ˆé€šè¿‡ OpenAI å…¼å®¹æ¥å£ï¼‰ç”Ÿæˆå‘¨æŠ¥...")
    report, token_usage = generate_weekly_report(articles)

    # è·å–æ—¥æœŸä»¥ä¾¿ç”Ÿæˆæ–‡æ¡£
    date = datetime.now().date()
    # å°†æŠ¥å‘Šå†™å…¥æ–‡ä»¶ï¼Œå¤´éƒ¨æ·»åŠ  Front Matterï¼ˆé€‚ç”¨äºé™æ€åšå®¢å¦‚ Hugoï¼‰
    with open(f"./_posts/{date}-Post.md", "w", encoding="utf-8") as f:
        if report is not None:
            f.write(f"""---
title: "AI Weekly Report({date})"
date: {date}
---
{report}
""")
        else:
            f.write("# æ— ç”Ÿæˆç»“æœ")
    
    print(f"ğŸ“„ å‘¨æŠ¥ç”ŸæˆæˆåŠŸï¼å·²ä¿å­˜è‡³: AI_Weekly_Reporter.md\nä½¿ç”¨Tokenï¼š{token_usage}")

"""æ—¥å¿—
æ­£åœ¨æŠ“å–æœ€è¿‘7å¤©çš„AIå‰æ²¿æ–‡ç« ...
Fetching: https://research.google/blog/rss/
Fetching: https://openai.com/news/rss.xml
Fetching: https://deepmind.com/blog/feed/
Fetching: https://huggingface.co/blog/feed.xml
Fetching: https://bair.berkeley.edu/blog/feed.xml
âœ… å…±è·å– 11 ç¯‡æ–°æ–‡ç« ã€‚
æ­£åœ¨è°ƒç”¨ Qwen-Maxï¼ˆé€šè¿‡ OpenAI å…¼å®¹æ¥å£ï¼‰ç”Ÿæˆå‘¨æŠ¥...
ğŸ“„ å‘¨æŠ¥ç”ŸæˆæˆåŠŸï¼å·²ä¿å­˜è‡³: AI_Weekly_Reporter.md
ä½¿ç”¨Tokenï¼š1566
"""
